trx$taxa <- ifelse(trx$taxa=="Ardea herodias", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Martes pennanti", "Mustelidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Martes pennanti", "Mustelidae", trx$taxa)
trx<-subset(trx, subset=c("camera", "image", "taxa", "checkedbyhand"))
trx<-subset(trx, select=c("camera", "image", "taxa", "checkedbyhand"))
View(trx)
rm(list=ls()) # remove everything currently held in the R memory
options(stringsAsFactors=FALSE)
graphics.off()
## Libraries
library(dplyr)
library(ggplot2)
#Load the data
results <- read.csv("~/Desktop/test_results_usda_all.csv", header=TRUE)
classes <- read.csv("~/Desktop/listofnames.csv", header=TRUE)
results$image <- gsub(".*/\\s*|'.*", '', results$fileName)
errors <- c(4, 17)
results$modelfix<-NA
results$modelfix <- ifelse(results$guess1==22, results$guess2, results$guess1)
results$modelfix <- ifelse(results$guess1==1, results$guess2, results$modelfix)
results$modelfix <- ifelse(results$modelfix%in%errors, 18, results$modelfix)
results$camera <- gsub("_.*", '', results$image)
classes$modelfix<-classes$Class.ID
classes$group<-classes$Group.name
classes$taxa<-classes$scientific_name
results <- left_join(results, classes)
tocheck <- read.csv("~/Documents/git/cameratrap/WildlifeDetections_CameraTrap.csv", header=TRUE)
trx<-subset(tocheck, select=c("Sampling.Event", "Raw.Name", "Genus", "Species"))
trx$image <- paste(trx$Sampling.Event, trx$Raw.Name, sep="_")
trx$taxa <- paste(trx$Genus, trx$Species, sep=" ")
trx$camera <- substr(trx$image, 0, 6)
trx$camera <- ifelse(trx$camera == "ATXing", substr(trx$image, 8, 13), trx$camera)
results$camera <- ifelse(results$camera=="CAM6A", "CAM06A", results$camera)
trx$taxa <- ifelse(trx$taxa=="Vulpes vulpes", "Vulpes vulpes and Urocyon Cinereoargentus", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Canis latrans", "Canidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Sciurus carolinensis", "Sciurus spp.", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Sylvilagus floridanus", "Leporidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Turdus migratorius", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Carduelis tristis", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Dumetella carolinensis", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Quiscalus quiscula", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Zenaida macroura", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Corvus brachyrhynchos", "Corvidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Urocyon cinereoargenteus", "Vulpes vulpes and Urocyon Cinereoargentus", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Passer domesticus", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Butorides virescens", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Neovison vison", "Mustelidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Cardinalis cardinalis", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Tamias striatus", "Rodentia", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Lontra canadensis", "Mustelidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Ardea herodias", "Aves", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Martes pennanti", "Mustelidae", trx$taxa)
trx$taxa <- ifelse(trx$taxa=="Martes pennanti", "Mustelidae", trx$taxa)
trx<-subset(trx, select=c("camera", "image", "taxa", "checkedbyhand"))
trx<-subset(trx, select=c("camera", "image", "taxa"))
trx <- left_join(trx, classes)
trx$checkedbyhand <- trx$Class.ID
trx <- subset(trx, select=c("image", "camera","checkedbyhand"))
goo <- left_join(results, trx)
goo <- full_join(results, trx)
howmanymatch <- unique(trx$image)
howmanymatch <- unique(trx$image)
foo <- goo[(goo$image%in%howmanymatch),]
View(foo)
goo <- left_join(results, trx)
howmanymatch <- unique(trx$image)
foo <- goo[(goo$image%in%howmanymatch),]
View(goo)
709/821
(exp(-0.48)-1)*100
(exp(0.14)-1)*100
(exp(0.4)-1)*100
(exp(0.19)-1)*100
(exp(0.35)-1)*100
(exp(0.42)-1)*100
(exp(-0.83)-1)*100
load("/Users/catchamberlain/Documents/git/regionalrisk/orig_full.Rdata")
orig.full
(exp(-0.12)-1)*100
broom::tidy(orig.full)
(exp(0.0008967095)-1)*100
load("/Users/catchamberlain/Documents/git/regionalrisk/bbmod.scaled.Rdata")
load("/Users/catchamberlain/Documents/git/regionalrisk/lstfrz.scaled.Rdata")
load("/Users/catchamberlain/Documents/git/regionalrisk/tmin.simple.Rdata")
bb.mod.scaled
lstfrz.mod.scaled
tmin.simple
lstfrz <- read.csv("~/Documents/git/regionalrisk/analyses/output/lastfreezedates.csv")
lstfrz$cc <- ifelse(lstfrz$year<=1983, 0, 1)
lstfrz$cc.z <- (lstfrz$cc-mean(lstfrz$cc,na.rm=TRUE))/(2*sd(lstfrz$cc,na.rm=TRUE))
colnames(lstfrz)
load("/Users/catchamberlain/Documents/git/regionalrisk/tminmod.Rdata")
tmin.mod
171-8
163/20
163/30
163-7
156/30
### Need to first build shapefiles...
pnw_long <- c(-123,  -123,  -119, -119)
pnw_lat <- c(52, 46, 52, 46)
pnw <- cbind(pnw_lat, pnw_long)
pnw
library(sp)
pnwpoly = Polygon(pnw)
pnwps = Polygons(list(pnw),1)
pnwsps = SpatialPolygons(pnw)
plot(pnw)
plot(pnwpoly)
st_write(pnw,
"~/Documents/git/microclimates/pnw.shp", driver = "ESRI Shapefile")
proj4string(pnw) = CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
require(sf)
install.packages("sf")
pnwshp<-st_as_sf(pnw)
require(sf)
pnwshp<-st_as_sf(pnw)
pnwshp<-st_as_sf(pnw, crs = "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
coordinates(pnw)=~long+lat
### Need to first build shapefiles...
pnw_long <- c(-123,  -123,  -119, -119)
pnw_lat <- c(52, 46, 52, 46)
pnw <- cbind(pnw_lat, pnw_long)
View(pnw)
### Need to first build shapefiles...
pnw <- data.frame(long=c(-123,  -123,  -119, -119), lat= c(52, 46, 52, 46))
coordinates(pnw)=~long+lat
proj4string(pnw)<- CRS("+proj=longlat +datum=WGS84")
LLcoor<-spTransform(pnw,CRS("+proj=longlat"))
pnwshp<-spTransform(pnw,CRS("+proj=longlat"))
(78824+2337+931+655+388+94+93+60+48+45+41+41+36+34+32+23+23+19+19+16+14+10+8+7+7+5+4+4+4+3+3+3+2+2+2+2+22)
(2788+13+8+17+34+2+2+1+1)
2866/83861
osp <- read.csv("~/Documents/git/ospree/analyses/input/ospree.csv")
ospfull <- read.csv("~/Documents/git/ospree/analyses/output/ospree_clean_withchill_BB_taxon.csv")
unique(osp$datasetID)
length(unique(osp$datasetID))
range(osp$year, na.rm=TRUE)
osp <- read.csv("~/Documents/git/ospree/analyses/output/ospree2019update.csv")
osp <- read.csv("~/Documents/git/ospree/analyses/output/ospree2019update.csv")
length(unique(osp$datasetID))
range(osp$year, na.rm=TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(ncdf4)
library(raster)
library(reshape2)
library(data.table)
dxx<-read.csv("~/Desktop/allspp_climateprep_midleaf.csv", header=TRUE)
dxx<-dxx[sample(nrow(dxx), 50), ]
r<-brick("~/Desktop/Big Data Files/tn_0.25deg_reg_v16.0.nc", varname="tn", sep="")
bb<-dxx
bb$lat.long<-paste(bb$lat, bb$long, sep=",")
bb<-bb[!duplicated(bb$lat.long),]
lats <- bb$lat
lons <- bb$long
coords <- data.frame(x=lons,y=lats)
coords<- na.omit(coords)
points <- SpatialPoints(coords, proj4string = r@crs)
values <- extract(r,points)
dclim <- cbind.data.frame(coordinates(points),values)
dx<-reshape2::melt(dclim, id.vars=c("x","y"))
dx<-dx%>%
dplyr::rename(long=x)%>%
dplyr::rename(lat=y)%>%
dplyr::rename(date=variable)%>%
dplyr::rename(Tmin=value)
dx$date<-substr(dx$date, 2,11)
dx$Date<- gsub("[.]", "-", dx$date)
dxx<-dplyr::select(dxx, -date)
dx<-dplyr::select(dx, -date)
x<-inner_join(dx, dxx, by=c("Date", "lat", "long"))
x$fs <- 0
x$fs<- ifelse(x$Tmin<=-2.2 & x$species%in%c("FAGSYL", "FRAEXC", "QUEROB"), 1, x$fs)
x$fs<- ifelse(x$Tmin<=-5 & x$species%in%c("AESHIP", "BETPEN", "ALNRUG"), 1, x$fs)
View(x)
dxx<-read.csv("/n/wolkovich_lab/Lab/Cat/allspp_climateprep_midleaf.csv", header=TRUE)
dxx<-read.csv("~/Desktop/allspp_climateprep_midleaf.csv", header=TRUE)
View(x)
dxx<-dxx[sample(nrow(dxx), 100), ]
r<-brick("/n/wolkovich_lab/Lab/Cat/tn_0.25deg_reg_v16.0.nc", varname="tn", sep="")
r<-brick("~/Desktop/Big Data Files/tn_0.25deg_reg_v16.0.nc", varname="tn", sep="")
bb<-dxx
bb$lat.long<-paste(bb$lat, bb$long, sep=",")
bb<-bb[!duplicated(bb$lat.long),]
lats <- bb$lat
lons <- bb$long
coords <- data.frame(x=lons,y=lats)
coords<- na.omit(coords)
points <- SpatialPoints(coords, proj4string = r@crs)
values <- extract(r,points)
dclim <- cbind.data.frame(coordinates(points),values)
dx<-reshape2::melt(dclim, id.vars=c("x","y"))
dx<-dx%>%
dplyr::rename(long=x)%>%
dplyr::rename(lat=y)%>%
dplyr::rename(date=variable)%>%
dplyr::rename(Tmin=value)
dx$date<-substr(dx$date, 2,11)
dx$Date<- gsub("[.]", "-", dx$date)
dxx<-dplyr::select(dxx, -date)
dx<-dplyr::select(dx, -date)
x<-inner_join(dx, dxx, by=c("Date", "lat", "long"))
x$fs <- 0
x$fs<- ifelse(x$Tmin<=-2.2 & x$species%in%c("FAGSYL", "FRAEXC", "QUEROB"), 1, x$fs)
x$fs<- ifelse(x$Tmin<=-5 & x$species%in%c("AESHIP", "BETPEN", "ALNRUG"), 1, x$fs)
# housekeeping
rm(list=ls())
options(stringsAsFactors = FALSE)
#### Questions to address:
## Compare GDDs between hobo loggers and weather station data
# 1) GDDlo ~ 1 + (1|species) - do once for HF weather station, once for hobo logger and repeat for Arboretum
# Compare urban effect using weather station data and then hobo logger data
# 2) GDDlo ~ urban + (urban|species) - do once with weather station data and once with hobo logger data
## Let's start with Question 1 first...
library(shinystan)
library(rstan)
## Let's load some real data to check out.
setwd("~/Documents/git/microclimates/analyses/")
#source("source/stan_utility.R")
urb <- read.csv("output/testdata_urbmethod.csv")
datalist.urb <- with(urb,
list(y = gdd,
tx = urban,
method = method,
sp = as.numeric(as.factor(species)),
N = nrow(urb),
n_sp = length(unique(species))
)
)
urbmethod_fake = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.urb,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
urbmethod_fake = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.urb,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
urbmethod_fake = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.urb,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
urbmethod_fake = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.urb,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
urbmethod_fake = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.urb,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
urbmethod_fake = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.urb,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
urbmethod_fake = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.urb,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
#### Now with real data
ws_urb <- read.csv("output/clean_gdd_bbanddvr.csv")
ws_urb$method <- "ws"
hobo_urb <- read.csv("output/clean_gdd_bbanddvr_hobo.csv")
hobo_urb$method <- "hobo"
View(urb)
View(ws_urb)
#### Now with real data
ws <- read.csv("output/clean_gdd_bbanddvr.csv")
ws$method <- "ws"
ws_urb <- subset(ws, select=c("id", "type", "gdd_bb", "method"))
ws_urb <- ws_urb[(ws_urb!="Common Garden"),]
View(ws_urb)
ws_urb <- subset(ws, select=c("id", "type", "gdd_bb", "method"))
ws_urb <- ws_urb[(ws_urb$type!="Common Garden"),]
#### Now with real data
ws <- read.csv("output/clean_gdd_bbanddvr.csv")
ws$method <- "ws"
ws_urb <- subset(ws, select=c("id", "type", "gdd_bb", "method", "year"))
ws_urb <- ws_urb[(ws_urb$type!="Common Garden"),]
View(ws_urb)
ws_urb <- ws_urb[(ws_urb$year=="2019"),]
hobo <- read.csv("output/clean_gdd_bbanddvr_hobo.csv")
hobo$method <- "hobo"
hobo_urb <- subset(hobo, select=c("id", "type", "gdd_bb", "method", "year"))
hobo_urb <- ws_urb[(hobo_urb$type!="Common Garden"),]
hobo_urb <- ws_urb[(hobo_urb$year=="2019"),]
View(hobo_urb)
bball <- full_join(ws_urb, hobo_urb)
bball <- dplyr::full_join(ws_urb, hobo_urb)
ws <- read.csv("output/clean_gdd_bbanddvr.csv")
ws$method <- 1
ws_urb <- subset(ws, select=c("id", "type", "gdd_bb", "method", "year"))
ws_urb <- ws_urb[(ws_urb$type!="Common Garden"),]
ws_urb <- ws_urb[(ws_urb$year=="2019"),]
hobo <- read.csv("output/clean_gdd_bbanddvr_hobo.csv")
hobo$method <- 0
hobo_urb <- subset(hobo, select=c("id", "type", "gdd_bb", "method", "year"))
hobo_urb <- ws_urb[(hobo_urb$type!="Common Garden"),]
hobo_urb <- ws_urb[(hobo_urb$year=="2019"),]
bball <- dplyr::full_join(ws_urb, hobo_urb)
bball$urban <- NA
bball$urban <- ifelse(bball$type=="Harvard Forest", 0, bball$urban)
bball$urban <- ifelse(bball$type=="Treespotters", 1, bball$urban)
View(ws)
ws <- read.csv("output/clean_gdd_bbanddvr.csv")
ws$method <- 1
ws_urb <- subset(ws, select=c("id", "type", "gdd_bb", "method", "year", "genus", "species"))
ws_urb <- ws_urb[(ws_urb$type!="Common Garden"),]
ws_urb <- ws_urb[(ws_urb$year=="2019"),]
hobo <- read.csv("output/clean_gdd_bbanddvr_hobo.csv")
hobo$method <- 0
hobo_urb <- subset(hobo, select=c("id", "type", "gdd_bb", "method", "year", "genus", "species"))
hobo_urb <- ws_urb[(hobo_urb$type!="Common Garden"),]
hobo_urb <- ws_urb[(hobo_urb$year=="2019"),]
bball <- dplyr::full_join(ws_urb, hobo_urb)
bball$urban <- NA
bball$urban <- ifelse(bball$type=="Harvard Forest", 0, bball$urban)
bball$urban <- ifelse(bball$type=="Treespotters", 1, bball$urban)
bball.stan <- subset(bball, select=c(gdd_bb, urban, method, genus, species))
bball.stan <- bball.stan[(complete.cases(bball.stan)),]
bball.stan$spp <- paste(bball.stan$genus, bball.stan$species, sep="_")
bball.stan <- bball.stan[(bball.stan$gdd_bb<=1000),]
View(bball)
bball.stan <-  na.omit(bball.stan)
View(bball)
bball.stan <- bball.stan[!is.na(bball.stan$gdd_bb),]
View(bball.stan)
ws <- read.csv("output/clean_gdd_bbanddvr.csv")
ws$method <- 1
ws_urb <- subset(ws, select=c("id", "type", "gdd_bb", "method", "year", "genus", "species"))
ws_urb <- ws_urb[(ws_urb$type!="Common Garden"),]
ws_urb <- ws_urb[(ws_urb$year=="2019"),]
hobo <- read.csv("output/clean_gdd_bbanddvr_hobo.csv")
hobo$method <- 0
hobo_urb <- subset(hobo, select=c("id", "type", "gdd_bb", "method", "year", "genus", "species"))
hobo_urb <- ws_urb[(hobo_urb$type!="Common Garden"),]
hobo_urb <- ws_urb[(hobo_urb$year=="2019"),]
bball <- dplyr::full_join(ws_urb, hobo_urb)
View(bball)
View(hobo)
View(hobo_urb)
### Weather data for the Arboretum downloaded from... http://labs.arboretum.harvard.edu/weather/
##  not using hobo loggers
### Weather data for Harvard Forests downloaded from... http://harvardforest.fas.harvard.edu:8080/exist/apps/datasets/showData.html?id=hf001
## and select 'hf001-10' - not using hobo loggers. Takes a while to download.
# ## housekeeping
rm(list=ls())
options(stringsAsFactors = FALSE)
## Load Libraries
library(dplyr)
library(tidyr)
library(geosphere)
library(anytime)
library(weathermetrics)
library(measurements)
library(lubridate)
library(chillR)
# Set Working Directory
setwd("~/Documents/git/microclimates/analyses")
d <- read.csv("output/clean_budburstandleafout.csv", header=TRUE)
## Flags for question
use.hobos <- TRUE ## make false if want to use main station climate data rather than the hobo loggers
if(use.hobos==FALSE){
# 1a. Let's add in climate data first for forcing.
source("calculating/clean_addinclimate.R") ## takes a while to load all the data, brings in climate data
#write.csv(cc, file="output/clean_addinclimate.csv", row.names=FALSE)
}
if(use.hobos==TRUE){
# 1b. Let's add in climate data from each hobo logger.
source("calculating/clean_addinclimate_loggers.R") ## takes a while to load all the data, brings in climate data
#write.csv(cc, file="output/clean_addinclimate.csv", row.names=FALSE)
}
# 2. Let's add in Forcing data first. We will use February 15 as the start
# of calculating GDD. Easy to fix if necessary in the gdd.start column
if(use.hobos==TRUE){
## Need to reset the working directory if use.hobos==TRUE.
setwd("~/Documents/git/microclimates/analyses")
}
source("calculating/calc_forceBB.R") ### This part can take a while depending on how many years of data you have and how many loggers
View(d)
View(forcebb)
# 2. Let's add in Forcing data for leafoutnow. We will again use February 15 as the start
# of calculating GDD. Easy to fix if necessary in the gdd.start column
source("calculating/calc_forceLO.R") ### This part can take a while depending on how many years of data you have and how many loggers
# 2. Let's add in Forcing data for leafoutnow. We will again use February 15 as the start
# of calculating GDD. Easy to fix if necessary in the gdd.start column
source("calculating/calc_forceLO.R") ### This part can take a while depending on how many years of data you have and how many loggers
# 3. Now let's add in forcing from budburst to leafout!! And also add in false spring information
source("calculating/calc_forceDVR.R") ### This part can take a while depending on how many years of data you have and how many loggers
# 4. Let's add in Chilling data for budburst now. We will use February 15 as the end
# of calculating chill and start with last observation from prev season. Easy to fix if necessary in the chill.startthis column
source("calculating/calc_chillports.R") ### This part can take a while depending on how many years of data you have and how many loggers
if(use.hobos==FALSE){
# 4. Let's add in tmean for the growing season for each individual - does climate play a roll on growing season length?
source("calculating/calc_gstmean.R")
}
if(use.hobos==FALSE){
# 5. Finally, let's add in precip for the growing season for each individual - does precip play a roll on growing season length?
source("calculating/calc_precip.R")
}
if(use.hobos==FALSE){
## If using 1a)...
write.csv(gdd.stan, file="output/clean_gdd_chill_bbanddvr.csv", row.names = FALSE)
}
if(use.hobos==TRUE){
## If using 1b)...
write.csv(gdd.stan, file="output/clean_gdd_chill_bbanddvr_hobo.csv", row.names = FALSE)
}
View(gdd.stan)
View(chillbb)
gdd.stan <- left_join(gdd.stan, chillbb)
View(gdd.stan)
## If using 1b)...
write.csv(gdd.stan, file="output/clean_gdd_chill_bbanddvr_hobo.csv", row.names = FALSE)
# housekeeping
rm(list=ls())
options(stringsAsFactors = FALSE)
#### Questions to address:
## Compare GDDs between hobo loggers and weather station data
# 1) GDDlo ~ 1 + (1|species) - do once for HF weather station, once for hobo logger and repeat for Arboretum
# Compare urban effect using weather station data and then hobo logger data
# 2) GDDlo ~ urban + (urban|species) - do once with weather station data and once with hobo logger data
## Let's start with Question 1 first...
library(shinystan)
library(rstan)
## Let's load some real data to check out.
setwd("~/Documents/git/microclimates/analyses/")
#### Now with real data
ws <- read.csv("output/clean_gdd_bbanddvr.csv")
ws$method <- 1
ws_urb <- subset(ws, select=c("id", "type", "gdd_bb", "method", "year", "genus", "species"))
ws_urb <- ws_urb[(ws_urb$type!="Common Garden"),]
ws_urb <- ws_urb[(ws_urb$year=="2019"),]
hobo <- read.csv("output/clean_gdd_bbanddvr_hobo.csv")
hobo$method <- 0
hobo_urb <- subset(hobo, select=c("id", "type", "gdd_bb", "method", "year", "genus", "species"))
hobo_urb <- ws_urb[(hobo_urb$type!="Common Garden"),]
hobo_urb <- ws_urb[(hobo_urb$year=="2019"),]
View(hobo_urb)
View(hobo)
hobo$method <- 0
View(hobo)
hobo_urb <- subset(hobo, select=c("id", "type", "gdd_bb", "method", "year", "genus", "species"))
hobo_urb <- hobo_urb[(hobo_urb$type!="Common Garden"),]
hobo_urb <- hobo_urb[(hobo_urb$year=="2019"),]
bball <- dplyr::full_join(ws_urb, hobo_urb)
bball$urban <- NA
bball$urban <- ifelse(bball$type=="Harvard Forest", 0, bball$urban)
bball$urban <- ifelse(bball$type=="Treespotters", 1, bball$urban)
bball.stan <- subset(bball, select=c(gdd_bb, urban, method, genus, species))
bball.stan <- bball.stan[(complete.cases(bball.stan)),]
bball.stan <- bball.stan[!is.na(bball.stan$gdd_bb),]
bball.stan$spp <- paste(bball.stan$genus, bball.stan$species, sep="_")
bball.stan <- bball.stan[(bball.stan$gdd_bb<=1000),]
datalist.gdd <- with(bball.stan,
list(y = gdd_bb,
tx = urban,
method = method,
sp = as.numeric(as.factor(spp)),
N = nrow(bball.stan),
n_sp = length(unique(bball.stan$spp))
)
)
urbmethod = stan('stan/urbanmethod_normal.stan', data = datalist.gdd,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
urbmethod_sum <- summary(urbmethod)$summary
urbmethod_sum[grep("mu_", rownames(urbmethod_sum)),]
urbmethod_sum[grep("sigma_", rownames(urbmethod_sum))[1:4],]
urbmethod = stan('stan/urbanmethod_normal.stan', data = datalist.gdd,
iter = 4000, warmup=2500, control=list(adapt_delta=0.90)) ###
yraw <- bball$gdd_bb
launch_shinystan(urbmethod)
launch_shinystan(urbmethod)
launch_shinystan(urbmethod)
rstanarm::launch_shinystan(urbmethod)
urbmethod = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.gdd,
iter = 4000, warmup=2500, control=list(adapt_delta=0.90)) ###
urbmethod_sum <- summary(urbmethod)$summary
urbmethod_sum[grep("mu_", rownames(urbmethod_sum)),]
urbmethod_sum[grep("sigma_", rownames(urbmethod_sum))[1:4],]
urbmethod_fake = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.urb,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
urbmethod = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.gdd,
iter = 4000, warmup=2500, control=list(adapt_delta=0.90)) ###
urbmethod_sum <- summary(urbmethod)$summary
urbmethod_sum[grep("mu_", rownames(urbmethod_sum)),]
urbmethod_sum[grep("sigma_", rownames(urbmethod_sum))[1:4],]
urbmethod = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.gdd,
iter = 4000, warmup=2500, control=list(adapt_delta=0.90)) ###
urbmethod = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.gdd,
iter = 4000, warmup=2500, control=list(adapt_delta=0.90)) ###
urbmethod_sum <- summary(urbmethod)$summary
urbmethod_sum[grep("mu_", rownames(urbmethod_sum)),]
urbmethod_sum[grep("sigma_", rownames(urbmethod_sum))[1:4],]
urbmethod = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.gdd,
iter = 4000, warmup=2500, control=list(adapt_delta=0.90)) ###
urbmethod_sum <- summary(urbmethod)$summary
urbmethod_sum[grep("mu_", rownames(urbmethod_sum)),]
urbmethod_sum[grep("sigma_", rownames(urbmethod_sum))[1:4],]
urb <- read.csv("output/testdata_urbmethod.csv")
datalist.urb <- with(urb,
list(y = gdd,
tx = urban,
method = method,
sp = as.numeric(as.factor(species)),
N = nrow(urb),
n_sp = length(unique(species))
)
)
urbmethod_fake = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.urb,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
urbmethod_fakesum <- summary(urbmethod_fake)$summary
urbmethod_fakesum[grep("mu_", rownames(urbmethod_fakesum)),]
urbmethod_fakesum[grep("sigma_", rownames(urbmethod_fakesum))[1:4],]
urbmethod_fakesum[grep("sigma_", rownames(urbmethod_fakesum)),]
urbmethod_fake = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.urb,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
urbmethod_fake = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.urb,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
urbmethod_fake = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.urb,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
urbmethod_fake = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.urb,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
urbmethod_fake = stan('stan/urbanmethod_normal_ncp.stan', data = datalist.urb,
iter = 2000, warmup=1000)#, control=list(adapt_delta=0.99)) ###
