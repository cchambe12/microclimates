rep(rnorm(n = 1, mean = model.parameters[[random.regex[3]]], sd = 50), ntot)}) ## change for interspecific variation, load sigma on species on prov paramter
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rnorm(n = 1, mean = mm[x, ] %*% parameters.temp[x, ], sd = 30)}) ## high individual variation, load sigma on sigma, less interspecific variation
fakedata_hl_urb_prov_sppvariation <- cbind(data.frame(species = as.vector(sapply(1:nsp, FUN = function(x) rep(x, ntot))),
gdd = response, urban = env.samples[,1], provenance = env.samples[,2]))
write.csv(fakedata_hl_urb_prov_sppvariation, file="output/fakedata_hl_urb_prov_sppvariation.csv", row.names = FALSE)
#  5) Let's do a quick lmer model to test the fake data
modtest <- lmer(gdd ~ urban + provenance + (urban + provenance|species), data=fakedata_hl_urb_prov_sppvariation) ## Quick look looks good!
}
modtest
rm(list=ls())
options(stringsAsFactors = FALSE)
#### Do some flagging to try all versions of the simulations
## Let's start with Question 1 first...
library(bayesplot) ## for plotting
library(egg) ## for plotting
library(shinystan)
library(rstanarm)
library(rstan)
library(brms)
## Let's load some real data to check out.
setwd("~/Documents/git/microclimates/analyses/")
source("source/stan_utility.R")
ws <- read.csv("output/clean_gdd_chill_bbanddvr.csv")
hobo <- read.csv("output/clean_gdd_chill_bbanddvr_hobo.csv")
mean(ws$gdd_bb, na.rm=TRUE) ## 300
mean(hobo$gdd_bb, na.rm=TRUE) ## 250
set.seed(12221)
use.hobo = FALSE ### We expect less species variation using weather station data, so if use.hobo=TRUE, then sigma will be loaded on overall error not on species
use.urban = TRUE
use.provenance = FALSE
use.highsitevariation = FALSE ## Not sure if I will use these but here just in case
use.highprovvariation = FALSE
check.diags = TRUE ## Do you want to check diagnostics?
save.stan = TRUE  ## Do you want to save your model?
if(use.urban==FALSE & use.highsitevariation==TRUE){
print("Error was made in flags!! Adjust accordingly!")
}
if(use.provenance==FALSE & use.highprovvariation==TRUE){
print("Error was made in flags!! Adjust accordingly!")
}
########################################################################
if (use.hobo==FALSE & use.urban==TRUE & use.provenance==FALSE &
use.highsitevariation==FALSE & use.highprovvariation==FALSE){
gdd.stan <- read.csv("output/fakedata_ws_urb.csv")
datalist.gdd <- with(gdd.stan,
list(y = gdd,
tx = urban,
sp = as.numeric(as.factor(species)),
N = nrow(gdd.stan),
n_sp = length(unique(gdd.stan$species))
)
)
ws_urb_fake = stan('stan/urbanmodel_stan_normal_weather.stan', data = datalist.gdd,
iter = 5000, warmup=2000, control=list(max_treedepth = 15,adapt_delta = 0.99)) ###
if(check.diags==TRUE){
check_all_diagnostics(ws_urb_fake)
}
ws_urb_fake.sum <- summary(ws_urb_fake)$summary
ws_urb_fake.sum[grep("mu_", rownames(ws_urb_fake.sum)),]
ws_urb_fake.sum[grep("sigma_", rownames(ws_urb_fake.sum)),]
if(save.stan==TRUE){
save(ws_urb_fake, file="~/Documents/git/microclimates/analyses/stan/ws_urban_stan.Rdata")
}
}
ws_urb_fake.sum[grep("mu_", rownames(ws_urb_fake.sum)),]
ws_urb_fake.sum[grep("sigma_", rownames(ws_urb_fake.sum)),]
rm(list=ls())
options(stringsAsFactors = FALSE)
## Let's start with Question 1 first...
library(bayesplot) ## for plotting
library(egg) ## for plotting
library(shinystan)
library(rstanarm)
library(rstan)
library(brms)
library(RColorBrewer)
library(dplyr)
## Let's load some real data to check out.
setwd("~/Documents/git/microclimates/analyses/")
figpath <- "figures"
use.hobo = FALSE ### We expect less species variation using weather station data, so if use.hobo=TRUE, then sigma will be loaded on overall error not on species
use.urban = TRUE
use.provenance = FALSE
use.highsitevariation = FALSE ## Not sure if I will use these but here just in case
use.highprovvariation = FALSE
if (use.hobo==FALSE & use.urban==TRUE & use.provenance==FALSE &
use.highsitevariation==FALSE & use.highprovvariation==FALSE){
figpathmore <- "ws_urb"
source("source/sigmasims_urban_muplot.R")
df <- read.csv("output/fakedata_ws_urb.csv")
y2 = 4
modelhere <- ws_urb_fake
}
rm(list=ls())
options(stringsAsFactors = FALSE)
#### Do some flagging to try all versions of the simulations
## Let's start with Question 1 first...
library(bayesplot) ## for plotting
library(egg) ## for plotting
library(shinystan)
library(rstanarm)
library(rstan)
library(brms)
## Let's load some real data to check out.
setwd("~/Documents/git/microclimates/analyses/")
source("source/stan_utility.R")
ws <- read.csv("output/clean_gdd_chill_bbanddvr.csv")
hobo <- read.csv("output/clean_gdd_chill_bbanddvr_hobo.csv")
mean(ws$gdd_bb, na.rm=TRUE) ## 300
mean(hobo$gdd_bb, na.rm=TRUE) ## 250
set.seed(12221)
use.hobo = FALSE ### We expect less species variation using weather station data, so if use.hobo=TRUE, then sigma will be loaded on overall error not on species
use.urban = TRUE
use.provenance = FALSE
use.highsitevariation = FALSE ## Not sure if I will use these but here just in case
use.highprovvariation = FALSE
#check.diags = TRUE ## Do you want to check diagnostics?
#save.stan = TRUE  ## Do you want to save your model?
if(use.urban==FALSE & use.highsitevariation==TRUE){
print("Error was made in flags!! Adjust accordingly!")
}
if(use.provenance==FALSE & use.highprovvariation==TRUE){
print("Error was made in flags!! Adjust accordingly!")
}
########################################################################
if (use.hobo==FALSE & use.urban==TRUE & use.provenance==FALSE &
use.highsitevariation==FALSE & use.highprovvariation==FALSE){
gdd.stan <- read.csv("output/fakedata_ws_urb.csv")
datalist.gdd <- with(gdd.stan,
list(y = gdd,
tx = urban,
sp = as.numeric(as.factor(species)),
N = nrow(gdd.stan),
n_sp = length(unique(gdd.stan$species))
)
)
ws_urb_fake = stan('stan/urbanmodel_stan_normal_weather.stan', data = datalist.gdd,
iter = 5000, warmup=2000, control=list(max_treedepth = 15,adapt_delta = 0.99)) ###
check_all_diagnostics(ws_urb_fake)
ws_urb_fake.sum <- summary(ws_urb_fake)$summary
ws_urb_fake.sum[grep("mu_", rownames(ws_urb_fake.sum)),]
ws_urb_fake.sum[grep("sigma_", rownames(ws_urb_fake.sum)),]
save(ws_urb_fake, file="~/Documents/git/microclimates/analyses/stan/ws_urban_stan.Rdata")
}
ws_urb_fake.sum[grep("mu_", rownames(ws_urb_fake.sum)),]
ws_urb_fake.sum[grep("sigma_", rownames(ws_urb_fake.sum)),]
save(ws_urb_fake, file="~/Documents/git/microclimates/analyses/stan/ws_urban_stan_sims.Rdata")
load("stan/ws_urban_stan_sims.Rdata")
figpathmore <- "ws_urb"
source("source/sigmasims_urban_muplot.R")
df <- read.csv("output/fakedata_ws_urb.csv")
y2 = 4
modelhere <- ws_urb_fake
figpath <- "figures"
# Set up colors
cols <- adjustcolor("indianred3", alpha.f = 0.3)
my.pal <- rep(brewer.pal(n = 11, name = "Spectral"), 4)
my.pal <- my.pal[my.pal!=c("#FFFFBF", "#FEE08B", "#E6F598")] ## removing light colors that are hard to see
my.pch <- rep(15:18, each=10)
alphahere = 0.4
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, 2)
spnum <- length(unique(df$spp))
spnum
unique(df$spp
)
View(df)
df <- read.csv("output/fakedata_ws_urb.csv")  ### Make sure species column is called `species`
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, 2)
source("source/sigmasims_urban_muplot.R")
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, 2)
modelhere
source("source/sigmasims_urban_prov_muplot.R")
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, 2)
pos.sps.i<-which(grepl(paste("[",spsi,"]",sep=""),rownames(summary(modelhere)$summary),fixed=TRUE))[1:2]
spnum <- length(unique(df$species))
source("source/sigmasims_urban_muplot.R")
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, 2)
modelhere
View(modelhere)
modcheck <- as.data.frame(modelhere)
View(modcheck)
colnames(modcheck)
y2 = 5
modelhere <- hl_urb_fake
modelhere <- ws_urb_fake
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, 2)
source("source/sigmasims_urban_muplot.R")
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, 2)
source("source/sigmasims_urban_muplot.R")
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, 2)
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, y2)
source("source/sigmasims_urban_muplot.R")
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, y2)
source("source/sigmasims_urban_muplot.R")
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, y2)
use.hobo = TRUE ### We expect less species variation using weather station data, so if use.hobo=TRUE, then sigma will be loaded on overall error not on species
use.urban = TRUE
use.provenance = FALSE
use.highsitevariation = FALSE ## Not sure if I will use these but here just in case
use.highprovvariation = FALSE
if(use.urban==FALSE & use.highsitevariation==TRUE){
print("Error was made in flags!! Adjust accordingly!")
}
if(use.provenance==FALSE & use.highprovvariation==TRUE){
print("Error was made in flags!! Adjust accordingly!")
}
########################################################################
if (use.hobo==FALSE & use.urban==TRUE & use.provenance==FALSE &
use.highsitevariation==FALSE & use.highprovvariation==FALSE){
gdd.stan <- read.csv("output/fakedata_ws_urb.csv")
datalist.gdd <- with(gdd.stan,
list(y = gdd,
tx = urban,
sp = as.numeric(as.factor(species)),
N = nrow(gdd.stan),
n_sp = length(unique(gdd.stan$species))
)
)
ws_urb_fake = stan('stan/urbanmodel_stan_normal_weather.stan', data = datalist.gdd,
iter = 5000, warmup=2000, control=list(max_treedepth = 15,adapt_delta = 0.99)) ###
check_all_diagnostics(ws_urb_fake)
ws_urb_fake.sum <- summary(ws_urb_fake)$summary
ws_urb_fake.sum[grep("mu_", rownames(ws_urb_fake.sum)),]
ws_urb_fake.sum[grep("sigma_", rownames(ws_urb_fake.sum)),]
save(ws_urb_fake, file="~/Documents/git/microclimates/analyses/stan/ws_urban_stan_sims.Rdata")
}
########################################################################
if (use.hobo==TRUE & use.urban==TRUE & use.provenance==FALSE &
use.highsitevariation==FALSE & use.highprovvariation==FALSE){
gdd.stan <- read.csv("output/fakedata_hl_urb.csv")
datalist.gdd <- with(gdd.stan,
list(y = gdd,
tx = urban,
sp = as.numeric(as.factor(species)),
N = nrow(gdd.stan),
n_sp = length(unique(gdd.stan$species))
)
)
hl_urb_fake = stan('stan/urbanmodel_stan_normal_weather.stan', data = datalist.gdd,
iter = 5000, warmup=2000, control=list(max_treedepth = 15,adapt_delta = 0.99)) ###
if(check.diags==TRUE){
check_all_diagnostics(hl_urb_fake)
}
hl_urb_fake.sum <- summary(hl_urb_fake)$summary
hl_urb_fake.sum[grep("mu_", rownames(hl_urb_fake.sum)),]
hl_urb_fake.sum[grep("sigma_", rownames(hl_urb_fake.sum)),]
if(save.stan==TRUE){
save(hl_urb_fake, file="~/Documents/git/microclimates/analyses/stan/hl_urban_stan_sims.Rdata")
}
}
hl_urb_fake.sum[grep("mu_", rownames(hl_urb_fake.sum)),]
hl_urb_fake.sum[grep("sigma_", rownames(hl_urb_fake.sum)),]
hl_urb_fake.sum <- summary(hl_urb_fake)$summary
hl_urb_fake.sum[grep("mu_", rownames(hl_urb_fake.sum)),]
hl_urb_fake.sum[grep("sigma_", rownames(hl_urb_fake.sum)),]
ws_urb_fake.sum[grep("mu_", rownames(ws_urb_fake.sum)),]
ws_urb_fake.sum[grep("sigma_", rownames(ws_urb_fake.sum)),]
save(hl_urb_fake, file="~/Documents/git/microclimates/analyses/stan/hl_urban_stan_sims.Rdata")
figpathmore <- "hl_urb"
source("source/sigmasims_urban_muplot.R")
df <- read.csv("output/fakedata_hl_urb.csv")
y2 = 5
modelhere <- hl_urb_fake
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, y2)
rm(list=ls())
options(stringsAsFactors = FALSE)
#### Do some flagging to try all versions of the simulations
# Load Libraries
library(RColorBrewer)
library(lme4)
## Let's load some real data to check out.
setwd("~/Documents/git/microclimates/analyses/")
ws <- read.csv("output/clean_gdd_chill_bbanddvr.csv")
hobo <- read.csv("output/clean_gdd_chill_bbanddvr_hobo.csv")
mean(ws$gdd_bb, na.rm=TRUE) ## 300
mean(hobo$gdd_bb, na.rm=TRUE) ## 250
set.seed(12221)
intercept = 300 ## We want to keep this the same between methods for now and just look into where the sigma is going
nsp = 20
ntot = 200
nsamples = 1000
#  1) Let's make the observations much higher than the actual data to build a good model.
nsp = nsp # number of species
ntot = ntot # numbers of obs per species.
sample_a <- list(site.env = rbinom(nsamples, 1, 0.5))
model.parameters <- list(intercept = intercept,
urban.coef = -150)
#  2) Now, we will make varying intercepts
env.samples <- sapply(sample_a, FUN = function(x){
sample(x, size = nsp * ntot, replace = TRUE)})
mm <- model.matrix(~env.samples)
#mm <- mm[,-2]
#  4) We need to make a random intercept model for each species
parameters.temp <- matrix(unlist(model.parameters), ncol = length(model.parameters), nrow = nsp * ntot, byrow = TRUE)
# Which parameters are random?
random.regex <- grep(pattern = paste(c("intercept", "urban.coef"), collapse = "|"), x = names(model.parameters))
# Generate random parameters (by species)
parameters.temp[, 1] <- sapply(1:nsp, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters[[random.regex[1]]], sd = 100), ntot)}) ## change for interspecific variation, load sigma on species on intercept
parameters.temp[, 2] <- sapply(1:nsp, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters[[random.regex[2]]], sd = 100), ntot)}) ## change for interspecific variation, load sigma on species on urban paramter
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rnorm(n = 1, mean = mm[x, ] %*% parameters.temp[x, ], sd = 200)}) ## high individual variation, load sigma on sigma, less interspecific variation
fakedata_ws_urb <- cbind(data.frame(species = as.vector(sapply(1:nsp, FUN = function(x) rep(x, ntot))),
gdd = response, urban = env.samples[,1]))
write.csv(fakedata_ws_urb, file="output/fakedata_ws_urb.csv", row.names = FALSE)
nsp = nsp # number of species
ntot = ntot # numbers of obs per species.
sample_a <- list(site.env = rbinom(nsamples, 1, 0.5))
model.parameters <- list(intercept = intercept,
urban.coef = -150)
#  2) Now, we will make varying intercepts
env.samples <- sapply(sample_a, FUN = function(x){
sample(x, size = nsp * ntot, replace = TRUE)})
mm <- model.matrix(~env.samples)
#mm <- mm[,-2]
#  4) We need to make a random intercept model for each species
parameters.temp <- matrix(unlist(model.parameters), ncol = length(model.parameters), nrow = nsp * ntot, byrow = TRUE)
# Which parameters are random?
random.regex <- grep(pattern = paste(c("intercept", "urban.coef"), collapse = "|"), x = names(model.parameters))
# Generate random parameters (by species)
parameters.temp[, 1] <- sapply(1:nsp, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters[[random.regex[1]]], sd = 200), ntot)}) ## change for interspecific variation, load sigma on species on intercept
parameters.temp[, 2] <- sapply(1:nsp, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters[[random.regex[2]]], sd = 100), ntot)}) ## change for interspecific variation, load sigma on species on urban paramter
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rnorm(n = 1, mean = mm[x, ] %*% parameters.temp[x, ], sd = 100)}) ## high individual variation, load sigma on sigma, less interspecific variation
fakedata_hl_urb <- cbind(data.frame(species = as.vector(sapply(1:nsp, FUN = function(x) rep(x, ntot))),
gdd = response, urban = env.samples[,1]))
write.csv(fakedata_hl_urb, file="output/fakedata_hl_urb.csv", row.names = FALSE)
nsp = nsp # number of species
ntot = ntot # numbers of obs per species.
sample_a <- list(site.env = rbinom(nsamples, 1, 0.5),
prov.env = rnorm(nsamples, 45, 10))
model.parameters <- list(intercept = intercept,
urban.coef = -150,
prov.coef = -100)
#  2) Now, we will make varying intercepts
env.samples <- sapply(sample_a, FUN = function(x){
sample(x, size = nsp * ntot, replace = TRUE)})
mm <- model.matrix(~env.samples)
#mm <- mm[,-2]
#  4) We need to make a random intercept model for each species
parameters.temp <- matrix(unlist(model.parameters), ncol = length(model.parameters), nrow = nsp * ntot, byrow = TRUE)
# Which parameters are random?
random.regex <- grep(pattern = paste(c("intercept", "urban.coef", "prov.coef"), collapse = "|"), x = names(model.parameters))
# Generate random parameters (by species)
parameters.temp[, 1] <- sapply(1:nsp, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters[[random.regex[1]]], sd = 100), ntot)}) ## change for interspecific variation, load sigma on species on intercept
parameters.temp[, 2] <- sapply(1:nsp, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters[[random.regex[2]]], sd = 100), ntot)}) ## change for interspecific variation, load sigma on species on urban paramter
parameters.temp[, 3] <- sapply(1:nsp, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters[[random.regex[3]]], sd = 100), ntot)}) ## change for interspecific variation, load sigma on species on prov paramter
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rnorm(n = 1, mean = mm[x, ] %*% parameters.temp[x, ], sd = 200)}) ## high individual variation, load sigma on sigma, less interspecific variation
fakedata_ws_urb_prov_sppvariation <- cbind(data.frame(species = as.vector(sapply(1:nsp, FUN = function(x) rep(x, ntot))),
gdd = response, urban = env.samples[,1], provenance = env.samples[,2]))
write.csv(fakedata_ws_urb_prov, file="output/fakedata_ws_urb_prov.csv", row.names = FALSE)
fakedata_ws_urb_prov <- cbind(data.frame(species = as.vector(sapply(1:nsp, FUN = function(x) rep(x, ntot))),
gdd = response, urban = env.samples[,1], provenance = env.samples[,2]))
write.csv(fakedata_ws_urb_prov, file="output/fakedata_ws_urb_prov.csv", row.names = FALSE)
#  1) Let's make the observations much higher than the actual data to build a good model.
nsp = nsp # number of species
ntot = ntot # numbers of obs per species.
sample_a <- list(site.env = rbinom(nsamples, 1, 0.5),
prov.env = rnorm(nsamples, 45, 10))
model.parameters <- list(intercept = intercept,
urban.coef = -150,
prov.coef = -100)
#  2) Now, we will make varying intercepts
env.samples <- sapply(sample_a, FUN = function(x){
sample(x, size = nsp * ntot, replace = TRUE)})
mm <- model.matrix(~env.samples)
#mm <- mm[,-2]
#  4) We need to make a random intercept model for each species
parameters.temp <- matrix(unlist(model.parameters), ncol = length(model.parameters), nrow = nsp * ntot, byrow = TRUE)
# Which parameters are random?
random.regex <- grep(pattern = paste(c("intercept", "urban.coef", "prov.coef"), collapse = "|"), x = names(model.parameters))
# Generate random parameters (by species)
parameters.temp[, 1] <- sapply(1:nsp, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters[[random.regex[1]]], sd = 200), ntot)}) ## change for interspecific variation, load sigma on species on intercept
parameters.temp[, 2] <- sapply(1:nsp, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters[[random.regex[2]]], sd = 100), ntot)}) ## change for interspecific variation, load sigma on species on urban paramter
parameters.temp[, 3] <- sapply(1:nsp, FUN = function(x){
rep(rnorm(n = 1, mean = model.parameters[[random.regex[3]]], sd = 100), ntot)}) ## change for interspecific variation, load sigma on species on prov paramter
# Calculate response
response <- sapply(1:nrow(env.samples), FUN = function(x){
rnorm(n = 1, mean = mm[x, ] %*% parameters.temp[x, ], sd = 100)}) ## high individual variation, load sigma on sigma, less interspecific variation
fakedata_hl_urb_prov <- cbind(data.frame(species = as.vector(sapply(1:nsp, FUN = function(x) rep(x, ntot))),
gdd = response, urban = env.samples[,1], provenance = env.samples[,2]))
write.csv(fakedata_hl_urb_prov, file="output/fakedata_hl_urb_prov.csv", row.names = FALSE)
rm(list=ls())
options(stringsAsFactors = FALSE)
#### Do some flagging to try all versions of the simulations
## Let's start with Question 1 first...
library(bayesplot) ## for plotting
library(egg) ## for plotting
library(shinystan)
library(rstanarm)
library(rstan)
library(brms)
## Let's load some real data to check out.
setwd("~/Documents/git/microclimates/analyses/")
source("source/stan_utility.R")
ws <- read.csv("output/clean_gdd_chill_bbanddvr.csv")
hobo <- read.csv("output/clean_gdd_chill_bbanddvr_hobo.csv")
mean(ws$gdd_bb, na.rm=TRUE) ## 300
mean(hobo$gdd_bb, na.rm=TRUE) ## 250
set.seed(12221)
use.hobo = FALSE ### We expect less species variation using weather station data, so if use.hobo=TRUE, then sigma will be loaded on overall error not on species
use.urban = TRUE
use.provenance = FALSE
use.highsitevariation = FALSE ## Not sure if I will use these but here just in case
use.highprovvariation = FALSE
if(use.urban==FALSE & use.highsitevariation==TRUE){
print("Error was made in flags!! Adjust accordingly!")
}
if(use.provenance==FALSE & use.highprovvariation==TRUE){
print("Error was made in flags!! Adjust accordingly!")
}
########################################################################
if (use.hobo==FALSE & use.urban==TRUE & use.provenance==FALSE &
use.highsitevariation==FALSE & use.highprovvariation==FALSE){
gdd.stan <- read.csv("output/fakedata_ws_urb.csv")
datalist.gdd <- with(gdd.stan,
list(y = gdd,
tx = urban,
sp = as.numeric(as.factor(species)),
N = nrow(gdd.stan),
n_sp = length(unique(gdd.stan$species))
)
)
ws_urb_fake = stan('stan/urbanmodel_stan_normal_weather.stan', data = datalist.gdd,
iter = 5000, warmup=2000, control=list(max_treedepth = 15,adapt_delta = 0.99)) ###
check_all_diagnostics(ws_urb_fake)
ws_urb_fake.sum <- summary(ws_urb_fake)$summary
ws_urb_fake.sum[grep("mu_", rownames(ws_urb_fake.sum)),]
ws_urb_fake.sum[grep("sigma_", rownames(ws_urb_fake.sum)),]
save(ws_urb_fake, file="~/Documents/git/microclimates/analyses/stan/ws_urban_stan_sims.Rdata")
}
ws_urb_fake = stan('stan/urbanmodel_stan_normal_weather.stan', data = datalist.gdd,
iter = 2000, warmup=1500) ###
check_all_diagnostics(ws_urb_fake)
ws_urb_fake.sum <- summary(ws_urb_fake)$summary
ws_urb_fake.sum[grep("mu_", rownames(ws_urb_fake.sum)),]
ws_urb_fake.sum[grep("sigma_", rownames(ws_urb_fake.sum)),]
save(ws_urb_fake, file="~/Documents/git/microclimates/analyses/stan/ws_urban_stan_sims.Rdata")
gdd.stan <- read.csv("output/fakedata_hl_urb.csv")
datalist.gdd <- with(gdd.stan,
list(y = gdd,
tx = urban,
sp = as.numeric(as.factor(species)),
N = nrow(gdd.stan),
n_sp = length(unique(gdd.stan$species))
)
)
hl_urb_fake = stan('stan/urbanmodel_stan_normal_weather.stan', data = datalist.gdd,
iter = 2000, warmup=1500) ###
check_all_diagnostics(hl_urb_fake)
hl_urb_fake.sum <- summary(hl_urb_fake)$summary
hl_urb_fake.sum[grep("mu_", rownames(hl_urb_fake.sum)),]
hl_urb_fake.sum[grep("sigma_", rownames(hl_urb_fake.sum)),]
save(hl_urb_fake, file="~/Documents/git/microclimates/analyses/stan/hl_urban_stan_sims.Rdata")
figpathmore <- "ws_urb"
source("source/sigmasims_urban_muplot.R")
df <- read.csv("output/fakedata_ws_urb.csv")  ### Make sure species column is called `species`
y2 = 5
modelhere <- ws_urb_fake
# Set up colors
cols <- adjustcolor("indianred3", alpha.f = 0.3)
my.pal <- rep(brewer.pal(n = 11, name = "Spectral"), 4)
my.pal <- my.pal[my.pal!=c("#FFFFBF", "#FEE08B", "#E6F598")] ## removing light colors that are hard to see
my.pch <- rep(15:18, each=10)
alphahere = 0.4
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, y2)
figpath <- "figures"
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, y2)
figpathmore <- "hl_urb"
source("source/sigmasims_urban_muplot.R")
df <- read.csv("output/fakedata_hl_urb.csv")
y2 = 5
modelhere <- hl_urb_fake
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, y2)
figpathmore <- "ws_urb"
source("source/sigmasims_urban_muplot.R")
df <- read.csv("output/fakedata_ws_urb.csv")  ### Make sure species column is called `species`
y2 = 5
modelhere <- ws_urb_fake
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, y2)
figpathmore <- "hl_urb"
source("source/sigmasims_urban_muplot.R")
df <- read.csv("output/fakedata_hl_urb.csv")
y2 = 5
modelhere <- hl_urb_fake
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, y2)
figpathmore <- "ws_urb"
source("source/sigmasims_urban_muplot.R")
df <- read.csv("output/fakedata_ws_urb.csv")  ### Make sure species column is called `species`
y2 = 5
modelhere <- ws_urb_fake
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, y2)
figpathmore <- "hl_urb"
source("source/sigmasims_urban_muplot.R")
df <- read.csv("output/fakedata_hl_urb.csv")
y2 = 5
modelhere <- hl_urb_fake
muplotfx(modelhere, "", 7, 8, c(0,y2), c(-400, 700) , 750, y2)
